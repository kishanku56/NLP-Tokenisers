# Tokenizer Implementations

This repository contains implementations of popular tokenization algorithms used in Natural Language Processing (NLP). Tokenizers transform raw text into tokens, enabling models to work with text effectively.

## Implemented Tokenizers
- **Byte-Level BPE (Byte Pair Encoding)**  
- **WordPiece**  
- **Unigram**  
- **SentencePiece (using Byte-Level BPE)**    

Vocab size, training file and test file has to be provided as command line arguments.
