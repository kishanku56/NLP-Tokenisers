# Tokenizer Implementations

This repository contains implementations of popular tokenization algorithms used in Natural Language Processing (NLP). Tokenizers transform raw text into tokens, enabling models to work with text effectively.

## Implemented Tokenizers
- **Byte-Level BPE (Byte Pair Encoding)**  
- **WordPiece**  
- **Unigram**  
- **SentencePiece (using Byte-Level BPE)**    

Vocab size, training file and test file has to be provided as command line arguments.

These tokenizers were implemented as part of the CS787 (Statistical Natural Language Processing) course assignment during my M.Tech at IIT Kanpur.
